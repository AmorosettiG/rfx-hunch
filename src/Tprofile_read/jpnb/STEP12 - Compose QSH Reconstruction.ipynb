{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunch models imported\n",
      "reload set for module  Hunch_utils\n",
      "reload set for module  Dummy_g1data\n",
      "reload set for module  Hunch_lsplot\n",
      "reload set for module  Hunch_tSNEplot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors \n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import ipysh\n",
    "\n",
    "%aimport models.base\n",
    "\n",
    "import Hunch_utils  as Htls\n",
    "import Hunch_lsplot as Hplt\n",
    "import Hunch_tSNEplot as Hsne\n",
    "\n",
    "%aimport Dataset_QSH\n",
    "\n",
    "%aimport models.AEFIT5\n",
    "%aimport models.Compose\n",
    "\n",
    "# ipysh.Bootstrap_support.debug()\n",
    "\n",
    "\n",
    "import livelossplot.keras\n",
    "class PlotLossesCallback(livelossplot.keras.PlotLossesCallback):\n",
    "    def on_train_batch_begin(self, a, b): pass\n",
    "    def on_train_batch_end(self, a, b): pass\n",
    "    def on_test_begin(self, a): pass\n",
    "    def on_test_end(self, a): pass\n",
    "    def on_test_batch_begin(self, a, b): pass\n",
    "    def on_test_batch_end(self, a, b): pass\n",
    "\n",
    "    \n",
    "class PlotRelevanceCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        fig.set_size_inches(13, 3)\n",
    "        w = self.model.layers[0].weights\n",
    "        ax1.bar(range(0,4), w[0][0:4])\n",
    "        labels = ['Ip','NS','Vt','F']\n",
    "        plt.sca(ax1)\n",
    "        plt.xticks(range(0,4), labels, fontsize=10)\n",
    "        ax2.bar(range(7,17), w[0][4:14])\n",
    "        plt.sca(ax2)\n",
    "        plt.xticks(range(7,17), fontsize=10)        \n",
    "        ax3.bar(range(7,17), w[0][14:24])\n",
    "        plt.sca(ax3)\n",
    "        plt.xticks(range(7,17), fontsize=10)       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST QSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSH rebalanced 15 points size:  47567\n"
     ]
    }
   ],
   "source": [
    "qsh = Dataset_QSH.Dataset_QSH()\n",
    "import os\n",
    "file = ipysh.abs_builddir+'/te_db_r15_clean.npy'\n",
    "try: qsh.load(file)\n",
    "except: raise FileNotFoundError\n",
    "    \n",
    "qsh.shuffle()\n",
    "qsh.dim = None\n",
    "qsh.set_null(np.nan)\n",
    "qsh.set_normal_positive(['prel','te','tbordo','tcentro', 'Ip','NS','VT','F'])\n",
    "# qsh.set_normal_positive(['prel','te','tbordo','tcentro', 'Ip','NS','VT','F','absBr_rm','argBr_rm'])\n",
    "# qsh.unbias_mean(0.5, 'te')\n",
    "# qsh.set_normal_positive(['te'])\n",
    "# qsh.clip_values(0.1,0.6)\n",
    "# qsh.set_normal_positive(['te'])\n",
    "\n",
    "\n",
    "print(\"QSH rebalanced 15 points size: \", len(qsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 16:33:34.006211 140306362611520 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:504: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "Br_min, Br_max = np.nanmin(qsh['Br_rm']), np.nanmax(qsh['Br_rm'])\n",
    "def _map(xy,p,Br):\n",
    "    Br = (Br-Br_min)/(Br_max-Br_min)\n",
    "    pBr = tf.concat([p,Br], axis=0)\n",
    "    return (xy,pBr),(xy,pBr)\n",
    "# ds = qsh.tf_tuple_compose(['prel','te','tbordo~tcentro~Ip~NS~VT~F','absBt_rm~argBt_rm']).map(lambda x,y,t,s: (_map(x,y,t,s)) )\n",
    "# ds = qsh.tf_tuple_compose(['prel~te:15','Ip~NS~VT~F','absBr_rm~argBr_rm']).map(lambda x,y,z: _map(x,y,z) )\n",
    "ds = qsh.tf_tuple_compose(['prel~te:15','Ip~NS~VT~F','Br_rm']).map(lambda x,y,z: _map(x,y,z) )\n",
    "# [x for x in ds.shuffle(100).batch(1).take(1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEFIT5 a ready:\n",
      "AEFIT5 a ready:\n",
      "AEFIT5 a ready:\n",
      "[(None, 30), (None, 24)]\n"
     ]
    }
   ],
   "source": [
    "m1 = models.AEFIT5.AEFIT5(latent_dim=2, feature_dim=30,  dprate=0., scale=1, geometry=[20,20,10,10], beta=0.) #beta=0.001)\n",
    "m2 = models.AEFIT5.AEFIT5(latent_dim=2, feature_dim=24,  dprate=0., scale=1, beta=0., name='parameters', geometry=[20,20,10,10]) # parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEFIT5 a ready:\n",
      "[(None, 30), (None, 24)]\n"
     ]
    }
   ],
   "source": [
    "hm_feature_dim = m1.latent_dim + m2.latent_dim\n",
    "hm = models.AEFIT5.AEFIT5(latent_dim=10, feature_dim=hm_feature_dim, beta=0., scale=1, name='hidden', geometry=[10,20,20,10])\n",
    "h = models.Compose.Compose().set_model(hm).compose([m1,m2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0144 - val_loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 0.0010 - val_loss: 4.4006e-04\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.9869e-04 - val_loss: 4.0692e-04\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.0567e-04 - val_loss: 5.7167e-04\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.0514e-04 - val_loss: 4.7666e-04\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 4.0440e-04 - val_loss: 4.1735e-04\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 4.3031e-04 - val_loss: 4.0857e-04\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 4.1309e-04 - val_loss: 4.0764e-04\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.3472e-04 - val_loss: 4.0537e-04\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 4.0617e-04 - val_loss: 4.5697e-04\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.3134e-04 - val_loss: 4.1181e-04\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.4307e-04 - val_loss: 4.1598e-04\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 3.9260e-04 - val_loss: 3.9971e-04\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.3330e-04 - val_loss: 4.2159e-04\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.9465e-04 - val_loss: 3.9586e-04\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.1891e-04 - val_loss: 3.9779e-04\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.9273e-04 - val_loss: 4.3977e-04\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.0961e-04 - val_loss: 4.2146e-04\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.0155e-04 - val_loss: 3.9843e-04\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.9315e-04 - val_loss: 4.0583e-04\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 4.0146e-04 - val_loss: 3.9232e-04\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.8690e-04 - val_loss: 4.0294e-04\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.8701e-04 - val_loss: 3.9287e-04\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.8885e-04 - val_loss: 3.8778e-04\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.7804e-04 - val_loss: 4.0011e-04\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 3.6745e-04 - val_loss: 3.5110e-04\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.9704e-04 - val_loss: 2.6147e-04\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.4392e-04 - val_loss: 2.4890e-04\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.3640e-04 - val_loss: 2.5139e-04\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 2.3228e-04 - val_loss: 2.4242e-04\n"
     ]
    }
   ],
   "source": [
    "ds_m1 = qsh.tf_tuple_compose(['prel~te:15']).map(lambda x: (x,x) )\n",
    "m1.compile( m1.optimizer, tf.losses.mse ) \n",
    "# m1.compile( ) \n",
    "# models.base.train_thread(m1, ds_m1, batch=100, epoch=50, callbacks=[]).control_panel()\n",
    "history = m1.fit( ds_m1.skip(5000).batch(100).take(100), validation_data=ds_m1.take(5000).batch(100), epochs=30 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d28dfd663439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSPlotBokeh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqsh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://172.17.0.2:8888'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andrea/devel/rfx/rfx-hunch/src/Tprofile_read/Hunch_lsplot.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, data, feed_data, counts)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfeed_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m                \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andrea/devel/rfx/rfx-hunch/src/Tprofile_read/Dataset_QSH.py\u001b[0m in \u001b[0;36mget_tf_dataset_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tf_dataset_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "qsh.dim = None\n",
    "p = Hplt.LSPlotBokeh()\n",
    "p.set_model(m1)\n",
    "p.set_data(qsh, counts=1000)\n",
    "p.plot(notebook_url='http://172.17.0.2:8888')\n",
    "\n",
    "# m1.save('step12_m1_compose')\n",
    "# m1.load('step12_m1_compose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 7s 70ms/step - loss: 0.0404 - val_loss: 0.0000e+00\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 6s 64ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 6s 62ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 6s 61ms/step - loss: 0.0019 - val_loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aa3bdf080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def m2_map(p,Br):\n",
    "    Br = (Br-Br_min)/(Br_max-Br_min)\n",
    "    pBr = tf.concat([p,Br], axis=0)\n",
    "    return pBr,pBr\n",
    "ds_m2 = qsh.tf_tuple_compose(['Ip~NS~VT~F','Br_rm']).map(lambda x,y: m2_map(x,y) )\n",
    "m2.compile( m2.optimizer, tf.losses.mse )\n",
    "# models.base.train_thread(m2, ds_m2, batch=100, epoch=10, callbacks=[]).control_panel()\n",
    "m2.fit( ds_m2.skip(5000).batch(100).take(100), validation_data=ds_m2.take(5000).batch(100), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.trainable = False\n",
    "m2.trainable = False\n",
    "hm.trainable = True\n",
    "h.loss_weights = [0.9,0.1]\n",
    "\n",
    "# l1 = tf.keras.regularizers.l1\n",
    "# l2 = tf.keras.regularizers.l2\n",
    "# for n in [hm.inference_net, hm.generative_net]:\n",
    "#     for l in n.layers:\n",
    "#         if issubclass(type(l), tf.keras.layers.Dense):\n",
    "#             l.activity_regularizer = l1(0.01)\n",
    "            \n",
    "# h.compile( h.optimizer, tf.losses.mse )\n",
    "h.compile( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.0026 - output_1_loss: 3.5914e-04 - output_2_loss: 0.0022 - val_loss: 0.0000e+00 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.0000e+00\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0024 - output_1_loss: 3.6067e-04 - output_2_loss: 0.0021 - val_loss: 0.0023 - val_output_1_loss: 3.3101e-04 - val_output_2_loss: 0.0020\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.0023 - output_1_loss: 3.2640e-04 - output_2_loss: 0.0020 - val_loss: 0.0024 - val_output_1_loss: 2.7888e-04 - val_output_2_loss: 0.0022\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0024 - output_1_loss: 3.2478e-04 - output_2_loss: 0.0021 - val_loss: 0.0025 - val_output_1_loss: 3.0140e-04 - val_output_2_loss: 0.0022\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0025 - output_1_loss: 3.6968e-04 - output_2_loss: 0.0022 - val_loss: 0.0025 - val_output_1_loss: 2.7195e-04 - val_output_2_loss: 0.0023\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0024 - output_1_loss: 3.1167e-04 - output_2_loss: 0.0021 - val_loss: 0.0027 - val_output_1_loss: 6.4784e-04 - val_output_2_loss: 0.0020\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.0025 - output_1_loss: 3.8761e-04 - output_2_loss: 0.0021 - val_loss: 0.0028 - val_output_1_loss: 3.0372e-04 - val_output_2_loss: 0.0025\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0024 - output_1_loss: 3.0923e-04 - output_2_loss: 0.0021 - val_loss: 0.0025 - val_output_1_loss: 2.8839e-04 - val_output_2_loss: 0.0022\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0024 - output_1_loss: 3.0364e-04 - output_2_loss: 0.0021 - val_loss: 0.0022 - val_output_1_loss: 2.9896e-04 - val_output_2_loss: 0.0019\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0025 - output_1_loss: 3.6117e-04 - output_2_loss: 0.0021 - val_loss: 0.0022 - val_output_1_loss: 2.8537e-04 - val_output_2_loss: 0.0019\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0024 - output_1_loss: 3.3370e-04 - output_2_loss: 0.0020 - val_loss: 0.0023 - val_output_1_loss: 2.8886e-04 - val_output_2_loss: 0.0021\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 8s 79ms/step - loss: 0.0024 - output_1_loss: 3.3117e-04 - output_2_loss: 0.0021 - val_loss: 0.0023 - val_output_1_loss: 2.8060e-04 - val_output_2_loss: 0.0020\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 8s 80ms/step - loss: 0.0024 - output_1_loss: 3.2014e-04 - output_2_loss: 0.0021 - val_loss: 0.0023 - val_output_1_loss: 2.7423e-04 - val_output_2_loss: 0.0020\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 8s 78ms/step - loss: 0.0023 - output_1_loss: 3.0408e-04 - output_2_loss: 0.0020 - val_loss: 0.0022 - val_output_1_loss: 2.9148e-04 - val_output_2_loss: 0.0019\n",
      "Epoch 15/200\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.0024 - output_1_loss: 3.1566e-04 - output_2_loss: 0.0021"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-13a47db1feeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# h.compile()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# models.base.train_thread(h, ds.take(10000) , epoch=100, batch=100, learning_rate=1e-3, callbacks=[PlotLossesCallback()]).control_panel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m--> 973\u001b[0;31m         x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2481\u001b[0m       \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2483\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2484\u001b[0m       \u001b[0;31m# Check that for stateful networks, number of samples is a multiple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m       \u001b[0;31m# of the static batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mstateful\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     return any((hasattr(layer, 'stateful') and layer.stateful)\n\u001b[0;32m--> 479\u001b[0;31m                for layer in self.layers)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     return any((hasattr(layer, 'stateful') and layer.stateful)\n\u001b[0;32m--> 479\u001b[0;31m                for layer in self.layers)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mstateful\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     return any((hasattr(layer, 'stateful') and layer.stateful)\n\u001b[0;32m--> 479\u001b[0;31m                for layer in self.layers)\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     return trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m--> 536\u001b[0;31m         self._layers)\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;31m# Trackable data structures will not show up in \".layers\" lists, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0;31m# the layers they contain will.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_layer_containers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       if (isinstance(obj, TrackableDataStructure)\n\u001b[0;32m--> 181\u001b[0;31m           \u001b[0;32mor\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m           or layer_utils.has_weights(obj)):\n\u001b[1;32m    183\u001b[0m         \u001b[0mcollected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hm.beta = 1.\n",
    "# h.compile()\n",
    "# models.base.train_thread(h, ds.take(10000) , epoch=100, batch=100, learning_rate=1e-3, callbacks=[PlotLossesCallback()]).control_panel()\n",
    "h.fit( ds.skip(5000).batch(100).take(100), validation_data=ds.take(5000).batch(100), epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAXXUlEQVR4nO3de5BcZ33m8e8zN9jYjuOyxyQljW6xvLIwiYwaWU7KAeJLyU6QUgESOTjBFdsKZMWmAptaYVIuolC7FShMVVKqbGTHXLIYYVMxO17klYNtFocwaFrR2CDJIsMgoVEopCjCWyxYMz3zyx/dozTjnukz06e7Ne88nypV9el+dc5v3u7znNPvubQiAjMzW/g62l2AmZnlw4FuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpaITIEuaZOko5KGJe2o8foySc9KOijpBUm351+qmZnNRvXOQ5fUCXwTuAUYBQaBOyLicFWb3cDBiPhLSWuBvRGxomlVm5nZK2TZQ98ADEfESESMAXuALdPaBPCTlceXAv+cX4lmZpZFV4Y2S4ATVdOjwPXT2nwQeErSe4CLgJtrzUjSNmAbwEUXXbR+zZo1c63XzGxRO3DgwL9ERG+t17IEehZ3AJ+IiI9KugH4G0nXRsRkdaOI2A3sBigUClEsFnNavJnZ4iDp+EyvZRlyOQn0VU0vrTxX7W7gUYCI+CrwauCKuZVpZmaNyBLog8BqSSsl9QBbgf5pbb4D3AQg6RrKgX46z0LNzGx2dQM9IkrAdmAfcAR4NCIOSdopaXOl2fuAeyU9D3wGuCt8G0czs5bKNIYeEXuBvdOeu7/q8WHgF/MtzczM5sJXipqZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWiEyBLmmTpKOShiXtqPH6xyQNVf59U9L38y/VzMxmU/c3RSV1AruAW4BRYFBSf+V3RAGIiD+sav8e4Lom1GpmZrPIsoe+ARiOiJGIGAP2AFtmaX8H8Jk8ijMzs+yyBPoS4ETV9GjluVeQtBxYCTzTeGlmZjYXeR8U3Qp8LiImar0oaZukoqTi6dOnc160mdniliXQTwJ9VdNLK8/VspVZhlsiYndEFCKi0Nvbm71KMzOrK0ugDwKrJa2U1EM5tPunN5K0BrgM+Gq+JZqZWRZ1Az0iSsB2YB9wBHg0Ig5J2ilpc1XTrcCeiIjmlGpmZrOpe9oiQETsBfZOe+7+adMfzK8sMzObK18pamaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZonIFOiSNkk6KmlY0o4Z2vyGpMOSDkl6JN8yzcysnro/Ei2pE9gF3AKMAoOS+iPicFWb1cD7gV+MiLOSrmxWwWZmVluWPfQNwHBEjETEGLAH2DKtzb3Arog4CxARp/It08zM6skS6EuAE1XTo5Xnql0NXC3pK5IGJG2qNSNJ2yQVJRVPnz49v4rNzKymvA6KdgGrgTcBdwAPSvqp6Y0iYndEFCKi0Nvbm9OizcwMsgX6SaCvanpp5blqo0B/RIxHxLeBb1IOeDMza5EsgT4IrJa0UlIPsBXon9bm85T3zpF0BeUhmJEc6zQzszrqBnpElIDtwD7gCPBoRByStFPS5kqzfcAZSYeBZ4E/iogzzSrazMxeSRHRlgUXCoUoFottWbaZ2UIl6UBEFGq95itFzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0uEA93MLBEOdDOzRDjQzcwS4UA3M0tEpkCXtEnSUUnDknbUeP0uSaclDVX+3ZN/qWZmNpuueg0kdQK7gFuAUWBQUn9EHJ7W9LMRsb0JNZqZWQZZ9tA3AMMRMRIRY8AeYEtzyzIzs7nKEuhLgBNV06OV56Z7q6QXJH1OUl+tGUnaJqkoqXj69Ol5lGtmZjPJ66DoE8CKiPg54O+AT9ZqFBG7I6IQEYXe3t6cFm1mZpAt0E8C1XvcSyvPnRcRZyLiXGXyIWB9PuWZmVlWWQJ9EFgtaaWkHmAr0F/dQNLPVE1uBo7kV6KZmWVR9yyXiChJ2g7sAzqBhyPikKSdQDEi+oH/LGkzUAL+FbiriTWbmVkNioi2LLhQKESxWGzLss3MFipJByKiUOs1XylqZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIyBbqkTZKOShqWtGOWdm+VFJJq/jySmZk1T91Al9QJ7AJuA9YCd0haW6PdJcAfAF/Lu0gzM6svyx76BmA4IkYiYgzYA2yp0e5PgT8DXs6xPjMzyyhLoC8BTlRNj1aeO0/S64G+iPjCbDOStE1SUVLx9OnTcy7WzMxm1vBBUUkdwAPA++q1jYjdEVGIiEJvb2+jizYzsypZAv0k0Fc1vbTy3JRLgGuBL0k6BmwE+n1g1MystbIE+iCwWtJKST3AVqB/6sWIeCkiroiIFRGxAhgANkdEsSkVm5lZTXUDPSJKwHZgH3AEeDQiDknaKWlzsws0M7NsurI0ioi9wN5pz90/Q9s3NV6WmZnNla8UNTNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRmQJd0iZJRyUNS9pR4/V3Sfq6pCFJfy9pbf6lmpnZbOoGuqROYBdwG7AWuKNGYD8SEa+LiHXAh4EHcq/UzMxmlWUPfQMwHBEjETEG7AG2VDeIiP9XNXkREPmVaGZmWXRlaLMEOFE1PQpcP72RpP8EvBfoAX651owkbQO2ASxbtmyutZqZ2SxyOygaEbsi4meB/wr88QxtdkdEISIKvb29eS3azMzIFugngb6q6aWV52ayB/i1RooyM7O5yxLog8BqSSsl9QBbgf7qBpJWV03+CvBP+ZVoZmZZ1B1Dj4iSpO3APqATeDgiDknaCRQjoh/YLulmYBw4C7yzmUWbmdkrZTkoSkTsBfZOe+7+qsd/kHNdZmY2R75S1MwsEQ50M7NEONDNzBLhQLeGDZ0a4qGvP8TQqaF2l2K2qGU6KGo2k6FTQ9z71L2MTYzR09nDg7c+yLor17W7LLNFyXvo1pDi94qMTYwxySTjk+MUv1dsd0lmi5YD3RpSeE2Bns4eOtVJd0c3hdcU2l2S2aLlIZfEDZ0aovi9IoXXFJoyFLLuynU8eOuDTV2GmWXjQE9Yq8a31125zkFudgHwkEvCPL5ttrg40BPm8W2zxcVDLgnz+LbZ4uJAT5zHt80WDw+5mJklwoFuZpYIB7qZWSIc6Bcg3+zKzObDB0UvML7ZlZnNV6Y9dEmbJB2VNCxpR43X3yvpsKQXJD0taXn+pS4OvhgoO3+TMftxdffQJXUCu4BbgFFgUFJ/RByuanYQKETEDyW9G/gw8JvNKDh1UxcDjU+O+2KgWfibjNkrZRly2QAMR8QIgKQ9wBbgfKBHxLNV7QeAO/MscjHxxUDZ1Pom476yxS5LoC8BTlRNjwLXz9L+buDJWi9I2gZsA1i2bFnGEhcfXwxUn7/JmL1SrgdFJd0JFIA31no9InYDuwEKhULkuWxbXPxNxuyVsgT6SaCvanpp5bkfI+lm4APAGyPiXD7lmc3M32TMflyWs1wGgdWSVkrqAbYC/dUNJF0H/BWwOSJO5V+mmZnVUzfQI6IEbAf2AUeARyPikKSdkjZXmn0EuBh4TNKQpP4ZZmdmZk2SaQw9IvYCe6c9d3/V45tzrsvMzObIl/6bmSXCgW5mlggHuplZIhzoZmaJcKA3yDeIWhz8PttC4NvnNsA3iFoc/D7bQuE99Ab4VreLg99nWygc6A2YukFUpzp9g6iE+X22hUIR7blHVqFQiGJx4e/pDJ0a8g2iFgG/z3ahkHQgImruVTjQzcwWkNkC3UMuFT6LwcwWOp/lgs9iMLM0eA8dn8VgZmlwoOOzGMwsDR5ywT9nNm8n9sOx52DFjdC3od3VmC16DvSKRn/O7MDxswyMnGHjqstZv/yyHCu7QJ3YD5/cDBNj0NkD7+xvfqi3YgPSjo3UtGX6FMnmWAzraDKB3s4368Dxs7zjoQHGSpP0dHXw6Xs2XjgfmGYF1LHniIlzKCaJiTF07LnmBmArNiDt2khVLXPo1x7g3qGP5X+AfpF/m7qg19EcJTGGPvVmffSpo7zjoQEOHD/b0uUPjJxhrDTJZMB4aZKBkTNznseB42fZ9exwrrW/OPhFxj/+q8QzHyqHxon9+c371T/Py5NdlKKDlyc7efHVP5/bvGs5OfQUk6VzEBPl8Dv2XP4LOfZced4xwWRpjJNDT+W/jBrLjIny3xUTYxRH9uV/gL6y0YhnPsT4x3+VFwe/2Pg8azhw/Cyf+/zfcvKJD+X2WctrvWhkHW3GutksmQJd0iZJRyUNS9pR4/VfkvSPkkqS3pZ/mbNrNFAbfcM2rrqcnq4OOgXdXR1sXHX5nJef9wbpwPGz7H3iMTQxfn4vOs8QfPoHK7hz/D4eKL2d3x6/j6d/sCK3eU934PhZ3rf/Es5FeQMy2dFd3tPM24obmezophQdnItO3rf/kqavxNM3jL2X3pj/Afqqb1OaGGfvE4/l/ncdOH6Wjzz0KX7l4O/xmuJHmfzEWxoO9al5/vDpD/ORhz7VUM3zXUen1s1n/u4J/u9f72jaxjAvdYdcJHUCu4BbgFFgUFJ/RByuavYd4C7gvzSjyHqm3qzx0uScAzWPr2Lrl1/Gp+/ZOO8hn4GRM7x24kWu7zjC/olrGBhZ3fDXwYGRM3yltIZ3d3dBlIiOLrpzDMGNqy7nLzrXMFS6mu6uDt4/x43YXAyMnGF/6SrewX3c0HmElddt4m3NGDbo28Dfvu4v+Xbx//DViWt4nqsYGDnT1K/mT/9gBc+M38f1OsL+uIY3T76JB28t5DuGvuJGSupGk+OM08U/lNbwqpz/roGRM6yPQ3RTokuTTE6Ml3cgGnifvn3wWT7e8SG6KTHO43zhYB/rl//6vOY133V0at38n93/jW5KxJOPw0//71n/rnYO/2YZQ98ADEfECICkPcAW4HygR8SxymuTTaixrkYCtdbefeb/XzUuuX75hnm/eTddfIzfrXxgxuni+MWvA66a17ymTAXub4/fxy90vcjtt72dNTmGYKMbsbmY2mA/X7qaw1rDp6/b2LRlrbzuzfzxgf/AOHPfOZiPWhvGdVdele/B0L4NfOu2R9j7xGP8Q2kN3+hck/sGeOOqy/nIM69lnMchSnR0Nf4t6obOw+c3EESJGzoPA/MLdID1Hf/E+q7noONGyrFW38ZVl3Ou68XzdUSUZt1QTd9B/Pzmbta8/HzLjl1kCfQlwImq6VHg+uaUM3/rl182r1C56eJjnOvuP/9Bz7wC53gAbc3LzxMdJRSTdGqi/AHg5nnNa8q/B+5qNq66izVNCNz59vl8ltOqjUcrl9XK5a15w838/yvX86qRM7y/spw8z6ZZv/wy/uie3+ELB/u4ofMwS9bd2nCALVl3K5NDf8HkxDgdXd3lec7XPNfX9csv46K3vJ148nEiSqizZ9YNVfUO4rUTL/KzT/53iFLLDrK39CwXSduAbQDLli2b1zxyPaXrxH7W7LuT/9h5jvd0dfOt2x7JHnxVB9DOH6Sb75u14kbU+SqYGKv7gZmLVgVuK7Tyb2l1v7Vywzi1nGbc7qI8/1+nkb3oH9O3gY67nsjn7JwG1tc1b7i5PMySoY7q4d9f6HqRrhiHmGw8IzLKEugngb6q6aWV5+YsInYDu6F8t8W5/v/cP4SVN1kxSTelue0Zr7ixvNWd2uI3EsJ9G8pb70V8Wpm1Vq3bXVyQ57z3bchnfWh0fc1YR/U3rpsufjva97/yyYiMsgT6ILBa0krKQb4V+K2mVjWD3D+EjbzJeYdwXh9cswymbncxPjm+OG53Mcv6mveFXP/+Tegq+OnW7qjVDfSIKEnaDuwDOoGHI+KQpJ1AMSL6Jb0BeBy4DHiLpD+JiNfmXez5D+HEGN1AQT/R2AwbDWWHsC1QrbjdxQV3xWuN9bXpd1ptcUZkGkOPiL3A3mnP3V/1eJDyUExTrbtyHQ+u+0OKT3+Awo9+xLrvvBcuvaqxDnMo2yLV6O0uZrNQbkm9YIaeMlpwV4quO/td7vn+S6x7+UfNu2LQzBqyUG5JndqdVhfevVzyPBhpZk3R7DH6vIZzGhl6uuCGlFiovym6yG80ZLYQNCvwLoThnEZqaLRfZvtN0YW3hw4e9zZbAJo1Rn8hjHvPt4Zmb4wW3Bi6mS1uF8K493xraPaxhYW5h25mi9aF8Atj862h2ccWFuYYupnZAuUxdDOzRDTz/H+PoZuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiMgW6pE2SjkoalrSjxuuvkvTZyutfk7Qi70LNzGx2dQNdUiewC7gNWAvcIWnttGZ3A2cj4irgY8Cf5V2omZnNLsse+gZgOCJGImIM2ANsmdZmC/DJyuPPATdJUn5lmplZPVlun7sEOFE1PQpcP1ObiChJegm4HPiX6kaStgHbKpM/kHRmeptF6ArcB+4D9wG4DyBbHyyf6YWW3g89InYDu6emJRVnulH7YuE+cB+A+wDcB9B4H2QZcjkJ9FVNL608V7ONpC7gUuDMfIsyM7O5yxLog8BqSSsl9QBbgf5pbfqBd1Yevw14Jtr123ZmZotU3SGXypj4dmAf0Ak8HBGHJO0EihHRD/w18DeShoF/pRz6Weyu3yR57gP3AbgPwH0ADfZB234k2szM8uUrRc3MEuFANzNLREsC3bcOyNQH75V0WNILkp6WNOO5pgtVvT6oavdWSSEpuVPYsvSBpN+ofBYOSXqk1TU2W4Z1YZmkZyUdrKwPt7ejzmaR9LCkU5K+McPrkvTnlf55QdLrM888Ipr6j/KB1G8Bq4Ae4Hlg7bQ2vw/8j8rjrcBnm11XK/9l7IM3Az9RefzuxdgHlXaXAF8GBoBCu+tuw+dgNXAQuKwyfWW7625DH+wG3l15vBY41u66c+6DXwJeD3xjhtdvB54EBGwEvpZ13q3YQ/etAzL0QUQ8GxE/rEwOUD7fPyVZPgcAf0r5XkAvt7K4FsnSB/cCuyLiLEBEnGpxjc2WpQ8C+MnK40uBf25hfU0XEV+mfDbgTLYAn4qyAeCnJP1Mlnm3ItBr3TpgyUxtIqIETN06IBVZ+qDa3ZS30Cmp2weVr5Z9EfGFVhbWQlk+B1cDV0v6iqQBSZtaVl1rZOmDDwJ3ShoF9gLvaU1pF4y55sV5Lb303+qTdCdQAN7Y7lpaSVIH8ABwV5tLabcuysMub6L8Le3Lkl4XEd9va1WtdQfwiYj4qKQbKF/jcm1ETLa7sAtdK/bQfeuAbH2ApJuBDwCbI+Jci2prlXp9cAlwLfAlSccojx32J3ZgNMvnYBToj4jxiPg28E3KAZ+KLH1wN/AoQER8FXg15ZtWLRaZ8qKWVgS6bx2QoQ8kXQf8FeUwT23cFOr0QUS8FBFXRMSKiFhB+TjC5ogotqfcpsiyLnye8t45kq6gPAQz0soimyxLH3wHuAlA0jWUA/10S6tsr37gdypnu2wEXoqI72b6ny06qns75T2NbwEfqDy3k/IKC+U37DFgGNgPrGr3keg29MEXge8BQ5V//e2uudV9MK3tl0jsLJeMnwNRHno6DHwd2NrumtvQB2uBr1A+A2YIuLXdNef8938G+C4wTvkb2d3Au4B3VX0GdlX65+tzWQ986b+ZWSJ8paiZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5kl4t8AshwIht73zdkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [ v.name for v in h2.trainable_variables ]\n",
    "def plot(xy):\n",
    "    plt.figure('data')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(0.,.8)\n",
    "    x,y = tf.split(xy[0], num_or_size_splits=2)\n",
    "    plt.plot(x,y,'.')\n",
    "d = [x for x in ds.shuffle(100).batch(1).take(100)][0]\n",
    "d0 = d[0][0]\n",
    "\n",
    "xy = d[0][0]\n",
    "XY = m1(xy, training=False)\n",
    "plot(xy)\n",
    "plot(XY)\n",
    "\n",
    "d_param = d[0]\n",
    "d_param = ( tf.zeros_like(d[0][0]), d[0][1] ) # spengo SXR e tengo i parametri\n",
    "# y0 = h(d[0], training=False)\n",
    "y0 = h(d_param, training=False)[0]\n",
    "# y0 = tf.sigmoid(y0)\n",
    "# plot(d0)\n",
    "plot(y0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbordo tcentro Ip NS VT F\n",
    "xy,_ =  [x for x in ds.batch(1).take(1)][0]\n",
    "par = xy[2]\n",
    "\n",
    "l,_ = h.encode(xy, training=False)\n",
    "XY  = h.decode(l, training=False, apply_sigmoid=True) \n",
    "PAR = XY[2]\n",
    "\n",
    "print( list(zip(par, PAR)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure('test_curve',figsize=(18, 6))\n",
    "plt.clf()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)    \n",
    "# ax1.set_xlim(-2.,2.)\n",
    "ax2.set_ylim(0.,1.)\n",
    "\n",
    "# sx = []\n",
    "# sy = []\n",
    "# for xy in ds.batch(1).take(1000):\n",
    "#     xy,_ = xy\n",
    "#     x,y = tf.split(xy[0],2, axis=1)\n",
    "#     me,_  = h.encode(xy, training=False)\n",
    "#     gpt = me[0].numpy()\n",
    "#     #ax1.scatter(gpt[0],gpt[1])\n",
    "#     sx.append(gpt[0])\n",
    "#     sy.append(gpt[1])\n",
    "\n",
    "# ax1.scatter(sx,sy)\n",
    "    \n",
    "for xy in ds.shuffle(100).batch(1).take(1):    \n",
    "    xy,_ = xy\n",
    "    x,y = tf.split(xy[0],2, axis=1)\n",
    "    ax2.scatter(x,y,s=80)\n",
    "    me,_  = h.encode(xy, training=False)\n",
    "    gpt = me[0].numpy()\n",
    "    ax1.scatter(gpt[0],gpt[1])\n",
    "    \n",
    "    XY = h.decode(me, training=False)[0]\n",
    "    XY = tf.sigmoid(XY)\n",
    "    X,Y = tf.split(XY[0], num_or_size_splits=2)\n",
    "    X,Y = (X.numpy(), Y.numpy())\n",
    "    ax2.scatter(X,Y,s=40)\n",
    "\n",
    "print(qsh_pos)    \n",
    "qsh_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy,_ = [x for x in ds.batch(2).take(1)][0]\n",
    "me,va = h.encode(xy)\n",
    "XY = h.decode(me, apply_sigmoid=True)\n",
    "XY[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
