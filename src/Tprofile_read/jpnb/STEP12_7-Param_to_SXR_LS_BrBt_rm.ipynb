{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunch models imported\n",
      "reload set for module  Hunch_utils\n",
      "reload set for module  Dummy_g1data\n",
      "reload set for module  Hunch_lsplot\n",
      "reload set for module  Hunch_tSNEplot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors \n",
    "# %matplotlib notebook\n",
    "\n",
    "import ipysh\n",
    "\n",
    "%aimport models.base\n",
    "\n",
    "import Hunch_utils  as Htls\n",
    "import Hunch_lsplot as Hplt\n",
    "import Hunch_tSNEplot as Hsne\n",
    "\n",
    "%aimport Dataset_QSH\n",
    "%aimport models.AEFIT5\n",
    "%aimport models.Compose\n",
    "%aimport models.GAN3\n",
    "\n",
    "import livelossplot.keras\n",
    "class PlotLossesCallback(livelossplot.keras.PlotLossesCallback):\n",
    "    def on_train_batch_begin(self, a, b): pass\n",
    "    def on_train_batch_end(self, a, b): pass\n",
    "    def on_test_begin(self, a): pass\n",
    "    def on_test_end(self, a): pass\n",
    "    def on_test_batch_begin(self, a, b): pass\n",
    "    def on_test_batch_end(self, a, b): pass\n",
    "\n",
    "    \n",
    "class PlotRelevanceCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "        fig.set_size_inches(13, 3)\n",
    "        w = self.model.layers[0].weights\n",
    "        ax1.bar(range(0,4), w[0][0:4])\n",
    "        labels = ['Ip','NS','Vt','F']\n",
    "        plt.sca(ax1)\n",
    "        plt.xticks(range(0,4), labels, fontsize=10)\n",
    "        ax2.bar(range(7,17), w[0][4:14])\n",
    "        plt.sca(ax2)\n",
    "        plt.xticks(range(7,17), fontsize=10)        \n",
    "        ax3.bar(range(7,17), w[0][14:24])\n",
    "        plt.sca(ax3)\n",
    "        plt.xticks(range(7,17), fontsize=10)       \n",
    "\n",
    "\n",
    "# ipysh.Bootstrap_support.debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST QSH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QSH rebalanced 15 points size:  47567\n"
     ]
    }
   ],
   "source": [
    "qsh = Dataset_QSH.Dataset_QSH()\n",
    "import os\n",
    "#file = ipysh.abs_builddir+'/te_db_r15_clean_shuffle.npy'\n",
    "file = ipysh.abs_builddir+'/te_db_r15u_shuffle.npy'\n",
    "try: qsh.load(file)\n",
    "except: raise FileNotFoundError\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# qsh.shuffle()\n",
    "qsh.dim = None\n",
    "qsh.set_null(np.nan)\n",
    "qsh.set_normal_positive(['prel','te','tbordo','tcentro', 'Ip','NS','VT','F','absBr_rm','argBr_rm','absBt_rm','argBt_rm']) \n",
    "print(\"QSH rebalanced 15 points size: \", len(qsh))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=57, shape=(1, 44), dtype=float32, numpy=\n",
       " array([[0.95069677, 0.63091564, 0.8925084 , 0.6560263 , 0.2558814 ,\n",
       "         0.03294136, 0.04579214, 0.03363009, 0.04979953, 0.04934926,\n",
       "         0.05426371, 0.0473731 , 0.07529996, 0.06970035, 0.89932925,\n",
       "         0.45932215, 0.91837114, 0.09220771, 0.5055865 , 0.6565236 ,\n",
       "         0.68972945, 0.86787784, 0.9692982 , 0.20216435, 0.23851517,\n",
       "         0.08621352, 0.0815101 , 0.04837004, 0.03239552, 0.04982209,\n",
       "         0.0329828 , 0.03390977, 0.04320031, 0.04005859, 0.07673635,\n",
       "         0.59453017, 0.02365356, 0.33110303, 0.65640765, 0.7272882 ,\n",
       "         0.8939708 , 0.97056895, 0.18887223, 0.31504267]], dtype=float32)>,\n",
       " <tf.Tensor: id=58, shape=(1, 30), dtype=float32, numpy=\n",
       " array([[0.02827343, 0.10277789, 0.15121816, 0.20828514, 0.27427357,\n",
       "         0.3485927 , 0.42948723, 0.51404023, 0.59859335, 0.6794879 ,\n",
       "         0.75380695, 0.8197954 , 0.8768625 ,        nan, 0.96593666,\n",
       "         0.2282556 , 0.22425407, 0.23232818, 0.22730592, 0.28690034,\n",
       "         0.31198397, 0.2804828 , 0.25904924, 0.24925506, 0.24683413,\n",
       "         0.22520164, 0.2228944 , 0.2316986 ,        nan, 0.13711277]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _map(xy,p,Br):\n",
    "    pBr = tf.concat([p,Br], axis=0)\n",
    "    return pBr,xy\n",
    "\n",
    "ds = qsh.tf_tuple_compose(['prel~te:15','Ip~NS~VT~F','absBr_rm~argBr_rm~absBt_rm~argBt_rm']).map(lambda x,y,br: _map(x,y,br) )\n",
    "[x for x in ds.shuffle(100).batch(1).take(1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEFIT5 a ready:\n"
     ]
    }
   ],
   "source": [
    "vae = models.AEFIT5.AEFIT5(latent_dim=6, feature_dim=30, dprate=0.1, beta=0., scale=2, geometry=[20,20,10,10])\n",
    "vae.compile( vae.optimizer, tf.losses.mse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "    177/Unknown - 13s 71ms/step - loss: 7.1568e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-10b5d75a416e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvae_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dds = ds.map(lambda p,xy: (xy,xy))\n",
    "vae_history = vae.fit( dds.skip(5000).batch(100, drop_remainder=True), validation_data=dds.take(5000).batch(100), epochs=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### vae.save('step12_vae_ls_tesi') \n",
    "vae.load('step12_vae_ls_tesi')\n",
    "\n",
    "# vae.inference_net.get_config()\n",
    "# tf.saved_model.save(vae.inference_net, '/tmp/thesis/vae/12_7/inference_net')\n",
    "# cacca = tf.saved_model.load('/tmp/thesis/vae/12_7/inference_net')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae1 = models.AEFIT5.AEFIT5(latent_dim=3, feature_dim=44, dprate=0.1, scale=2, geometry=[20,20,10,10])\n",
    "vae1.generative_net.trainable = False\n",
    "gen = vae1.inference_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dds = ds.map(lambda p,xy: (p, tf.reshape(vae.encode(tf.reshape(xy,[1,-1]),training=False)[0],[-1])) )\n",
    "[x for x in Dds.batch(1).take(1)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "rel = gen.layers[0]\n",
    "rel.rate = 0.\n",
    "gen.compile( tf.optimizers.Adam(1e-3), tf.losses.mse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = lambda: gen.fit( Dds.skip(3000).batch(100), validation_data=Dds.take(3000).batch(100), epochs=400,\n",
    "                      callbacks=[PlotLossesCallback()], shuffle=False )\n",
    "models.base.fn_thread(gen, fit).control_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# save this image as:  STEP12_7_pBr2SXR_rm-rs_absarg_training_mse.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae1.save('step12_7_thesis_BrBt')\n",
    "vae1.load('step12_7_thesis_BrBt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = qsh[0].n\n",
    "w = gen.layers[1].weights\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_bar_x(index, w, title, w2=None):\n",
    "    # this is for plotting purpose\n",
    "    fig = plt.figure(title)\n",
    "    fig.set_dpi(150)\n",
    "    plt.bar(index, w, color='lightgrey', edgecolor='black')    \n",
    "    plt.ylabel('SXR relevance', fontsize=10)\n",
    "    plt.xticks(index, fontsize=10)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "p,abs_Brm,arg_Brm,abs_Brs,arg_Brs = w[0][0:4],w[0][4:14], w[0][14:24], w[0][24:34], w[0][34:44]\n",
    "plot_bar_x(['Ip','NS','Vt','F'], p, 'params')\n",
    "plot_bar_x(index, abs_Brm, 'abs $B_{rm}$ m=1 modes relevance')\n",
    "plot_bar_x(index, arg_Brm, 'arg $B_{rm}$ m=1 modes relevance')\n",
    "plot_bar_x(index, abs_Brs, 'abs $B_{rs}$ m=1 modes relevance')\n",
    "plot_bar_x(index, arg_Brs, 'arg $B_{rs}$ m=1 modes relevance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos)\n",
    "\n",
    "\n",
    "def un(x, min=0., max=2242.511):\n",
    "    return min + x*(max-min)\n",
    "\n",
    "def unx(x, min=-0.373, max=0.353):\n",
    "    return min + x*(max-min)\n",
    "\n",
    "def plot_tf(xy, name=None, h='.'):\n",
    "    fig = plt.figure('plot')    \n",
    "    fig.set_dpi(150)\n",
    "    ax = plt.gca()    \n",
    "    ax.set_ylim(0.,un(0.8))\n",
    "    xy = tf.reshape(xy, [-1])\n",
    "    x,y = tf.split(xy, num_or_size_splits=2, axis=0)\n",
    "    plt.plot(unx(x),un(y),h, label=name)\n",
    "    ax.legend()\n",
    "\n",
    "def plot(x,y, name=None, h='.'):  \n",
    "    fig = plt.figure('plot')    \n",
    "    fig.set_dpi(150)\n",
    "    ax = plt.gca()    \n",
    "    ax.set_ylim(0.,un(0.8))\n",
    "    plt.plot(unx(x),un(y), h, label=name)\n",
    "    #ax.legend()\n",
    "    \n",
    "def plot_bar_x(index, w, title, w2=None):\n",
    "    # this is for plotting purpose\n",
    "    fig = plt.figure(title)\n",
    "    plt.clf()\n",
    "    fig.set_dpi(150)\n",
    "    plt.bar(index, w, color='lightgrey', edgecolor='black')    \n",
    "    # plt.ylabel('plasma parameters', fontsize=10)\n",
    "    plt.xticks(index, fontsize=10)\n",
    "    plt.title(title)\n",
    "    return fig\n",
    "    \n",
    "def plot_te(pos):    \n",
    "    d_pos = [x for x in ds.skip(pos).batch(1).take(1)][0]\n",
    "    path = '/home/andrea/Documents/phd/Thesis/img/STEP12/STEP12_7'\n",
    "    p  = d_pos[0]\n",
    "    xy = d_pos[1]\n",
    "\n",
    "    fig = plt.figure('plot')\n",
    "    plt.clf()\n",
    "    # plt.text(0.05,0.7, '$I_p = %.2f$'%qsh[pos]['Ip'] )\n",
    "    ax = plt.gca()\n",
    "    ax.set_title( 'Te reconstruction [eV]   '+qsh[pos].label.decode(\"utf-8\") )\n",
    "\n",
    "    XY_vae = vae(xy, training=False)\n",
    "    ls = gen(d_pos[0], training=False)\n",
    "    XY = vae.decode(ls, training=False)\n",
    "    # XY = tf.sigmoid(XY)\n",
    "    plot_tf(xy, '$T_e$','-.')\n",
    "    plot_tf(XY_vae, 'ls6','+')\n",
    "    plot_tf(XY, 'guess','x')\n",
    "    plot(qsh[pos]['prel'],qsh[pos]['te'], '$T_c$')\n",
    "\n",
    "    fig2 = plt.figure('contour')\n",
    "    plt.clf()\n",
    "    ax2  = plt.gca()\n",
    "    fig2.set_dpi(150)\n",
    "    qsh[pos].plot_countour(ax=ax2)\n",
    "    #ax2.set_title('SHeq')\n",
    "    fig2.savefig( path+'/Contour_'+str(pos)+'.png')\n",
    "\n",
    "    fig3 = plot_bar_x(['Ip [MA]\\n(0.4, 0.8)',\n",
    "                       'NS \\n(2.5, 7.7)',\n",
    "                       'Vt [V]\\n(161, 272)',\n",
    "                       'F  \\n(-0.26, 0.02)'], qsh[pos]['Ip~NS~VT~F'], 'nomalized plasma parameters')\n",
    "    fig3.savefig( path+'/Params_'+str(pos)+'.png')\n",
    "\n",
    "    fig = plt.figure('plot')\n",
    "    fig.savefig( path+'/Te_rec_'+str(pos)+'.png')\n",
    "\n",
    "for pos in range(250):\n",
    "    plot_te(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [q for q in ds.batch(2).take(1)][0]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = {\n",
    "    'mse' : [],\n",
    "    'sum_e' : [],\n",
    "#    'sum_ve': [],\n",
    "    'max' : [],\n",
    "    'min' : [],\n",
    "    'Ip' : [],\n",
    "    'NS' : [],\n",
    "    'Vt' : [],\n",
    "    'F'  : [],\n",
    "}\n",
    "fig = plt.figure()\n",
    "\n",
    "def un(x, min, max):\n",
    "    return min + x*(max-min)\n",
    "\n",
    "for i,d_pos in enumerate(ds.batch(300).take(10)):\n",
    "    p  = d_pos[0]\n",
    "    xy = d_pos[1]\n",
    "    XY_vae = vae(xy, training=False)\n",
    "    ls = gen(d_pos[0], training=False)\n",
    "    XY = vae.decode(ls, training=False)\n",
    "    \n",
    "    prel = tf.split(p, split_)\n",
    "    \n",
    "    mse = tf.losses.mse(XY_vae,XY)\n",
    "    sum_e = tf.reduce_sum( (XY_vae-XY), axis=1) / 15\n",
    "    max_e = tf.reduce_max( XY_vae-XY, axis=1) \n",
    "    min_e = tf.reduce_min( XY_vae-XY, axis=1) \n",
    "    # plot_tf(XY_vae, 'ls6','+')\n",
    "    # plot_tf(XY, 'guess','x')\n",
    "    for i in range(300):\n",
    "        loss['mse'].append( un(mse[i].numpy(),0.,2242.511) )\n",
    "        loss['sum_e'].append( un(sum_e[i].numpy(),0.,2242.511)  )\n",
    "        loss['max'].append( un(max_e[i].numpy()-min_e[i].numpy(),0.,2242.511)  )\n",
    "        loss['min'].append( un(min_e[i].numpy()-max_e[i].numpy(),0.,2242.511)  )\n",
    "        loss['Ip'].append( un(p[i][0].numpy(),0.41,0.79) )\n",
    "        loss['NS'].append( un(p[i][1].numpy(),2.55,7.69) )\n",
    "        loss['Vt'].append( un(p[i][2].numpy(),161.15, 272.39) ) \n",
    "        loss['F'].append(p[i][3].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "#x = np.clip( np.array(loss['sum_e']), a_min=-200., a_max=200. )\n",
    "lim = 200.\n",
    "lim_f = 200.\n",
    "x = np.array(loss['sum_e'])\n",
    "X_in  = x[ (x > -lim_f) & (x < lim_f) ]\n",
    "X_out = x[ (x < -lim_f) | (x > lim_f) ]\n",
    "\n",
    "ax = sns.distplot( x, kde=False ,norm_hist=True, hist_kws={\"range\": [-lim,lim], \"histtype\": \"step\", \"linewidth\": 2, \"color\": \"k\"} );\n",
    "\n",
    "xx = np.arange(-lim,lim, 0.1)\n",
    "mu,std = stats.norm.fit(X_in)\n",
    "yy = stats.norm.pdf(xx,mu,std)\n",
    "ax.plot(xx,yy,'--k', label='norm')\n",
    "\n",
    "# mu,std = stats.logistic.fit(x)\n",
    "# yy = stats.logistic.pdf(xx,mu,std)\n",
    "# ax.plot(xx,yy,'-.r', label='N_2')\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_dpi(150)\n",
    "plt.xlim(-190,190)\n",
    "#plt.legend()\n",
    "\n",
    "ax.set_title('mean SRX reconstruction error')\n",
    "\n",
    "plt.text(100,0.006,'$\\sigma = %.2f$\\nKurt $= %.2f$'%(x.std(),stats.kurtosis(x)))\n",
    "\n",
    "print('norm',stats.norm.fit(x))\n",
    "print('kurt',stats.kurtosis(x))\n",
    "print('logistic',stats.logistic.fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "#x = np.clip( np.array(loss['sum_e']), a_min=-200., a_max=200. )\n",
    "lim = 200.\n",
    "x = loss['max']\n",
    "# x = x[ x < lim ]\n",
    "# x = x[ x > -lim ]\n",
    "\n",
    "ax = sns.distplot( x, kde=False, norm_hist=True, hist_kws={\"range\": [-lim,lim]} );\n",
    "\n",
    "xx = np.arange(-lim,lim, 0.1)\n",
    "mu,std = stats.norm.fit(x)\n",
    "yy = stats.norm.pdf(xx,mu,std)\n",
    "ax.plot(xx,yy,'--k', label='norm')\n",
    "\n",
    "mu,std = stats.logistic.fit(x)\n",
    "yy = stats.logistic.pdf(xx,mu,std)\n",
    "ax.plot(xx,yy,'-.r', label='logisitc')\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_dpi(150)\n",
    "# plt.xlim(-190,190)\n",
    "plt.legend()\n",
    "\n",
    "ax.set_title('max SRX error distribution')\n",
    "print('norm',stats.norm.fit(x))\n",
    "print('logistic',stats.logistic.fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loss['mse']))\n",
    "fig = plt.figure('params vs mse')\n",
    "fig.set_dpi(150)\n",
    "ax = plt.gca()\n",
    "ax.set_title('Ip [MA] vs mse on reconstructed SXR')\n",
    "# plt.yscale('log')\n",
    "# plt.plot(loss['Ip'],loss['mse'],'+')\n",
    "plt.plot(loss['Ip'],np.log(loss['max']),'x')\n",
    "# plt.plot(loss['NS'],loss['mse'],'x')\n",
    "# plt.plot(loss['Vt'],loss['mse'],'.')\n",
    "# plt.plot(loss['F'],loss['mse'],'.')\n",
    "\n",
    "fig = plt.figure('Ip hist')\n",
    "fig.set_dpi(150)\n",
    "ax = plt.gca()\n",
    "ax.set_title('Ip [MA] vs mse on reconstructed SXR')\n",
    "plt.hist2d(loss['Ip'], np.log(loss['max']), (50, 50), cmap=plt.cm.jet)\n",
    "# plt.hist2d(loss['Ip'], loss['sum_e'], (50, 50), cmap=plt.cm.jet)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loss['mse']))\n",
    "fig = plt.figure('params vs mse')\n",
    "fig.set_dpi(150)\n",
    "ax = plt.gca()\n",
    "ax.set_title('NS vs mse on reconstructed SXR')\n",
    "plt.yscale('log')\n",
    "plt.plot(loss['NS'],loss['mse'],'+')\n",
    "\n",
    "\n",
    "fig = plt.figure('NS hist')\n",
    "ax = plt.gca()\n",
    "ax.set_title('NS vs log(mse) on reconstructed SXR')\n",
    "fig.set_dpi(150)\n",
    "plt.hist2d(loss['NS'], np.log(loss['mse']), (50, 50), cmap=plt.cm.jet)\n",
    "# plt.colorbar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
