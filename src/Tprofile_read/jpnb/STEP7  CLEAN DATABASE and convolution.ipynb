{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors \n",
    "\n",
    "import ipysh\n",
    "import Hunch_utils  as Htls\n",
    "import Hunch_lsplot as Hplt\n",
    "import Hunch_tSNEplot as Hsne\n",
    "\n",
    "%aimport Dataset_QSH\n",
    "\n",
    "%aimport models.base\n",
    "%aimport models.AEFIT5\n",
    "%aimport models.CAEFIT\n",
    "%aimport models.CAEFIT1\n",
    "\n",
    "\n",
    "\n",
    "import livelossplot.keras\n",
    "class PlotLossesCallback(livelossplot.keras.PlotLossesCallback):\n",
    "    def on_train_batch_begin(self, a, b): pass\n",
    "    def on_train_batch_end(self, a, b): pass\n",
    "    def on_test_begin(self, a): pass\n",
    "    def on_test_end(self, a): pass\n",
    "    def on_test_batch_begin(self, a, b): pass\n",
    "    def on_test_batch_end(self, a, b): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh = Dataset_QSH.Dataset_QSH()\n",
    "import os\n",
    "file = ipysh.abs_builddir+'/te_db_r15u.npy'\n",
    "if os.path.isfile(file):\n",
    "    qsh.load(file)\n",
    "else:\n",
    "    qsh.load(ipysh.abs_builddir+'/te_db_1.npy')    \n",
    "    qsh.rebalance_prel(15)\n",
    "    qsh.save(ipysh.abs_builddir+'/te_db_r15u.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh.shuffle()\n",
    "# qsh.filter_number_set(15)\n",
    "qsh.clean_up_poorcurves(5)\n",
    "qsh.dim = 15\n",
    "qsh.set_null(np.nan)\n",
    "qsh.set_normal_positive()\n",
    "# qsh.unbias_mean(0.5, 'te')\n",
    "# qsh.set_normal_positive()\n",
    "\n",
    "print(\"QSH rebalanced 15 points size: \", len(qsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qsh.set_null(np.nan)\n",
    "# qsh.clip_values(0.1,0.6)\n",
    "# qsh.set_normal_positive()\n",
    "# qsh.set_null(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh.set_null(-1)\n",
    "sne = Htls.tSNE()\n",
    "# sne.perplexity = 50.\n",
    "sne.random = 42\n",
    "\n",
    "ds = qsh[range(0,4000)]\n",
    "ds = np.concatenate([ds['prel'],ds['te']], axis=1)\n",
    "# ds = np.array(list(zip(ds['prel'],ds['te'])))\n",
    "sne(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()\n",
    "\n",
    "p = Hsne.tSNE_PlotBokeh()\n",
    "p.set_model(sne)\n",
    "p.set_data(qsh, 1000)\n",
    "p.plot(notebook_url='http://172.17.0.2:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE reconstruction - beta\n",
    "\n",
    "The dropout has been set to 0. ... otherwise it seems to not converge ( tested with 0.4 )\n",
    "Moreover also beta has been set to 0. ... that corresponds to a deterministic vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %aimport models.base\n",
    "#%aimport models.AEFIT2\n",
    "# %aimport models.AEFIT3\n",
    "# q_vae = models.AEFIT2.AEFIT2(latent_dim=2, feature_dim=30, dprate=0., scale=4, beta=0.)\n",
    "#q_vae = models.AEFIT5.AEFIT5(latent_dim=2, feature_dim=30, dprate=0., scale=1, beta=0.000001, geometry=[20,20,10,10])\n",
    "q_vae = models.AEFIT5.AEFIT5(latent_dim=30, feature_dim=30, dprate=0., scale=1, beta=0.000001, geometry=[20,20,10,10])\n",
    "# im1 = tf.keras.utils.plot_model(q_vae.inference_net, show_shapes=True, rankdir='LR')\n",
    "# im2 = tf.keras.utils.plot_model(q_vae.generative_net, show_shapes=True, rankdir='LR')\n",
    "# from IPython.display import display\n",
    "# display(im1)\n",
    "# display(im2)\n",
    "# q_vae.compile( tf.optimizers.Adam(1e-3), tf.losses.mse )\n",
    "# q_vae.compile( tf.optimizers.Adam(1e-3), q_vae.compute_cross_entropy_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Hplt.LSPlotBokeh()\n",
    "p.set_model(q_vae)\n",
    "p.set_data(qsh, counts=1000)\n",
    "p.plot(notebook_url='http://172.17.0.2:8888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = qsh.ds_array.map(lambda x,l: (x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.base.manual_train_thread(q_vae, qsh, batch=200, epoch=6, loss_factor=1e-3)\n",
    "# q_vae.train_thread(qsh, batch=200, epoch=10, learning_rate=1e-3).control_panel()\n",
    "# models.base.train_thread(q_vae, qsh, batch=100, epoch=10, learning_rate=1e-3, callbacks=[]).control_panel()\n",
    "def fun():\n",
    "    global h\n",
    "    h = q_vae.fit( ds.skip(3000).batch(100, drop_remainder=True), validation_data=ds.take(3000).batch(100), epochs=200, shuffle=False)\n",
    "models.base.fn_thread(fn=fun, model=q_vae).control_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [i[0] for i in h.history['loss']]\n",
    "val_loss = [i[0] for i in h.history['val_loss']]\n",
    "fig = plt.figure('loss')\n",
    "fig.set_dpi(150)\n",
    "plt.yscale('log')\n",
    "plt.plot(loss[0:150])\n",
    "plt.plot(val_loss[0:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_vae.save('step7_beta0_r15_1')\n",
    "q_vae.save('step7_beta0001_r15_ls2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_vae.load('step7_beta0_r15_1')\n",
    "q_vae.load('step7_beta0001_r15_ls2_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract few points curve\n",
    "import copy\n",
    "\n",
    "qsh2 = Dataset_QSH.Dataset_QSH()\n",
    "qsh2.load(ipysh.abs_builddir+'/te_db_r15u.npy')\n",
    "qsh2.dim = 15\n",
    "qsh2.set_null(np.nan)\n",
    "qsh2.set_normal_positive()\n",
    "# qsh2.unbias_mean(0.5, 'te')\n",
    "# qsh2.set_normal_positive()\n",
    "qsh2.set_null(np.nan)\n",
    "# qsh2.clip_values(0.1,0.6)\n",
    "# qsh2.set_normal_positive()\n",
    "\n",
    "qsh2.filter_number_set(5)\n",
    "qsh2.dim = 15\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 25\n",
    "pos = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure('gen_missing_curve',figsize=(18, 6))\n",
    "fig.set_dpi(150)\n",
    "plt.clf()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)    \n",
    "# ax1.set_xlim(-2.,2.)\n",
    "ax2.set_ylim(0.,0.5)\n",
    "\n",
    "# print(q_vae.apply_sigmoid)\n",
    "print(pos)\n",
    "# qsh2.shuffle()\n",
    "for xy in qsh2.ds_array.skip(pos).batch(1).take(1):\n",
    "    ax2.set_title('Missing data inputation with $VAE_2$ on %s'%qsh2[pos].label.decode(\"utf-8\") )\n",
    "    xy,_ = xy\n",
    "    # print(xy)\n",
    "    x,y = tf.split(xy[0],2)\n",
    "    ax2.scatter(x,y,s=120, label='real input')\n",
    "    m,v  = q_vae.encode(xy, training=False)    \n",
    "    gpt = m[0].numpy()\n",
    "    # print(gpt)\n",
    "    ax1.scatter(gpt[0],gpt[1])\n",
    "\n",
    "    XY = q_vae.decode(m, training=False)\n",
    "    X,Y = tf.split(XY[0], 2)\n",
    "    X,Y = (X.numpy(), Y.numpy())\n",
    "\n",
    "    ax2.scatter(X,Y,s=180, marker='+', label='$VAE_2$ inputed')\n",
    "    ax2.legend()\n",
    "pos += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN QSH DATABASE\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "qsh_clean = copy.deepcopy(qsh)\n",
    "\n",
    "print( q_vae.apply_sigmoid )\n",
    "\n",
    "ds = qsh.ds_array\n",
    "for i,X in enumerate(tqdm(ds.batch(1), total=len(qsh))):\n",
    "    X,_ = X\n",
    "    s   = int(q_vae.feature_dim/2)\n",
    "    Xr  = q_vae.recover(X)\n",
    "    x,y = tf.split(Xr, 2, axis=1)\n",
    "    qsh_clean[i].prel[:s] = x\n",
    "    qsh_clean[i].te[:s]   = y\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh_clean.save(ipysh.abs_builddir+'/te_db_r15_clean.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh_clean = Htls.QSH_Dataset()\n",
    "qsh_clean.load(ipysh.abs_builddir+'/te_db_r15_clean.npy')\n",
    "qsh_clean.dim = 15\n",
    "qsh_clean.set_null(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE on clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh_clean.set_null(-1)\n",
    "sne = Htls.tSNE()\n",
    "# sne.perplexity = 50.\n",
    "sne.random = 42\n",
    "\n",
    "ds = qsh_clean[0:2000]\n",
    "ds = np.concatenate([ds['prel'],ds['te']], axis=1)\n",
    "sne(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()\n",
    "\n",
    "p = Hsne.tSNE_PlotBokeh()\n",
    "p.set_model(sne)\n",
    "p.set_data(qsh_clean, 1000)\n",
    "p.plot(notebook_url='http://172.17.0.2:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae = models.CAEFIT.CAEFIT(latent_dim=2, feature_dim=30, dprate=0., scale=2, beta=0.)\n",
    "\n",
    "# im1 = tf.keras.utils.plot_model(cae.inference_net, show_shapes=True, rankdir='LR')\n",
    "# im2 = tf.keras.utils.plot_model(cae.generative_net, show_shapes=True, rankdir='LR')\n",
    "# from IPython.display import display\n",
    "# display(im1)\n",
    "# display(im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae = models.CAEFIT1.CAEFIT1(latent_dim=2, feature_dim=30, dprate=0., scale=2, beta=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = qsh_clean.ds_array\n",
    "ds0,_ = [x for x in ds.take(1).batch(1)][0]\n",
    "ds0\n",
    "me,va = cae.encode(ds0)\n",
    "y = cae.decode(me, apply_sigmoid=True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train(cae, qsh_clean, batch=200, epoch=10, loss_factor=1e-4)\n",
    "# models.base.train(cae, qsh_clean, batch=200, epoch=2, loss_factor=1e-3)\n",
    "models.base.train(cae, qsh_clean, batch=200, epoch=2, loss_factor=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.base.train_thread(cae, qsh_clean, batch=200, epoch=5, learning_rate=1e-3).control_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipysh.Bootstrap_support.debug()\n",
    "\n",
    "p = Hplt.LSPlotBokeh()\n",
    "p.set_model(cae)\n",
    "p.set_data(qsh_clean, counts=1000)\n",
    "p.plot_notebook(notebook_url='http://172.17.0.2:8888')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cae.save('step7_cae_r15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae.load('step7_cae_r15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh_pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure('test_curve',figsize=(18, 6))\n",
    "plt.clf()\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)    \n",
    "# ax1.set_xlim(-2.,2.)\n",
    "ax2.set_ylim(0.,1.)\n",
    "\n",
    "\n",
    "for xy in qsh_clean.ds_array.skip(qsh_pos).take(1):    \n",
    "    xy,_ = xy\n",
    "    x,y = tf.split(xy,2)\n",
    "    ax2.scatter(x,y,s=80)\n",
    "    m,v  = cae.encode([xy], training=False)\n",
    "    gpt = m[0].numpy()\n",
    "    ax1.scatter(gpt[0],gpt[1])\n",
    "    \n",
    "    XY = cae.decode(m,apply_sigmoid=True, training=False)\n",
    "    X,Y = tf.split(XY[0], 2)\n",
    "    X,Y = (X.numpy(), Y.numpy())\n",
    "    ax2.scatter(X,Y,s=40)\n",
    "\n",
    "print(qsh_pos)    \n",
    "qsh_pos += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
