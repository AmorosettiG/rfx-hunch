{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors \n",
    "\n",
    "import ipysh\n",
    "import Hunch_utils  as Htls\n",
    "import Hunch_lsplot as Hplt\n",
    "import Hunch_tSNEplot as Hsne\n",
    "\n",
    "%aimport Dataset_QSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.stats import StatsOp\n",
    "from brevitas.nn import QuantConv2d, QuantHardTanh, QuantLinear\n",
    "# Quant common\n",
    "BIT_WIDTH_IMPL_TYPE = BitWidthImplType.CONST\n",
    "SCALING_VALUE_TYPE = RestrictValueType.LOG_FP\n",
    "SCALING_IMPL_TYPE = ScalingImplType.PARAMETER\n",
    "NARROW_RANGE_ENABLED = True\n",
    "\n",
    "# Weight quant common\n",
    "STATS_OP = StatsOp.MEAN_LEARN_SIGMA_STD\n",
    "BIAS_ENABLED = False\n",
    "WEIGHT_SCALING_IMPL_TYPE = ScalingImplType.STATS\n",
    "SIGMA = 0.001\n",
    "\n",
    "# QuantHardTanh configuration\n",
    "HARD_TANH_MIN = -1.0\n",
    "HARD_TANH_MAX = 1.0\n",
    "ACT_PER_OUT_CH_SCALING = False\n",
    "\n",
    "def get_stats_op(quant_type):\n",
    "    if quant_type == QuantType.BINARY:\n",
    "        return StatsOp.AVE\n",
    "    else:\n",
    "        return StatsOp.MAX\n",
    "\n",
    "\n",
    "def get_quant_type(bit_width):\n",
    "    if bit_width is None:\n",
    "        return QuantType.FP\n",
    "    elif bit_width == 1:\n",
    "        return QuantType.BINARY\n",
    "    else:\n",
    "        return QuantType.INT\n",
    "\n",
    "\n",
    "def get_act_quant(act_bit_width, act_quant_type):\n",
    "    if act_quant_type == QuantType.INT:\n",
    "        act_scaling_impl_type = ScalingImplType.PARAMETER\n",
    "    else:\n",
    "        act_scaling_impl_type = ScalingImplType.CONST\n",
    "    return QuantHardTanh(quant_type=act_quant_type,\n",
    "                         bit_width=act_bit_width,\n",
    "                         bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                         min_val=HARD_TANH_MIN,\n",
    "                         max_val=HARD_TANH_MAX,\n",
    "                         scaling_impl_type=act_scaling_impl_type,\n",
    "                         restrict_scaling_type=SCALING_VALUE_TYPE,\n",
    "                         scaling_per_channel=ACT_PER_OUT_CH_SCALING,\n",
    "                         narrow_range=NARROW_RANGE_ENABLED)\n",
    "\n",
    "\n",
    "def get_quant_linear(in_features, out_features, per_out_ch_scaling, bit_width, quant_type, stats_op):\n",
    "    return QuantLinear(bias=BIAS_ENABLED,\n",
    "                       in_features=in_features,\n",
    "                       out_features=out_features,\n",
    "                       weight_quant_type=quant_type,\n",
    "                       weight_bit_width=bit_width,\n",
    "                       weight_bit_width_impl_type=BIT_WIDTH_IMPL_TYPE,\n",
    "                       weight_scaling_per_output_channel=per_out_ch_scaling,\n",
    "                       weight_scaling_stats_op=stats_op,\n",
    "                       weight_scaling_stats_sigma=SIGMA)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.quant import RescalingIntQuant\n",
    "\n",
    "INTERMEDIATE_FC_PER_OUT_CH_SCALING = True\n",
    "LAST_FC_PER_OUT_CH_SCALING = False\n",
    "IN_DROPOUT = 0.2\n",
    "HIDDEN_DROPOUT = 0.2\n",
    "\n",
    "\n",
    "weight_quant_type = get_quant_type(1)\n",
    "act_quant_type = get_quant_type(1)\n",
    "in_quant_type = get_quant_type(1)\n",
    "stats_op = get_stats_op(weight_quant_type)\n",
    "# INT-8\n",
    "class TestModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(TestModel, self).__init__()\n",
    "        self.fc1 = get_quant_linear(in_features=30,\n",
    "                                    out_features=30,\n",
    "                                    per_out_ch_scaling=INTERMEDIATE_FC_PER_OUT_CH_SCALING,\n",
    "                                    bit_width=1,\n",
    "                                    quant_type=weight_quant_type,\n",
    "                                    stats_op=stats_op)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #         out = self.relu3(self.fc1(x))\n",
    "        #         out = self.relu4(self.fc2(out))\n",
    "        #         out = self.fc3(out)\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsh = Dataset_QSH.Dataset_QSH()\n",
    "file = ipysh.abs_builddir+'/te_db_r15_clean_shuffle.npy'\n",
    "qsh.load(file)\n",
    "\n",
    "qsh.dim = 15\n",
    "qsh.set_null(np.nan)\n",
    "qsh.set_normal_positive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "ds = qsh.get_torch_dataset(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5300, -0.1324,  0.0214, -0.3962, -0.5261,  0.4405, -0.2946,  0.1931,\n",
       "         -0.1001, -0.1119,  0.2916, -1.3516, -0.1463,  0.5977, -0.3714, -0.6793,\n",
       "          0.3242,  0.0601, -0.0283,  0.1863, -0.2546,  0.4349,  0.5386, -0.0071,\n",
       "          0.2733, -0.3356,  0.2590,  0.4032, -0.0746,  0.0745]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = TestModel()\n",
    "x = torch.randn(1, 30, requires_grad=True)\n",
    "X = m(x)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brevitas.onnx as bo\n",
    "bo.export_finn_onnx(m,(1,30),'/tmp/test_bo.onnx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
